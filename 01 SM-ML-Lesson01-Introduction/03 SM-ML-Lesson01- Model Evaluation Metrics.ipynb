{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4654ee3e-418b-4c18-95a3-ff7687587e86",
   "metadata": {},
   "source": [
    "### Model Evaluation Metrics\n",
    "\n",
    "Model evaluation metrics are essential tools used to assess the performance of machine learning models. They help quantify how well a model is performing and provide insights into its strengths and weaknesses. The choice of evaluation metrics depends on the type of problem (classification, regression, etc.) and the specific goals of the model deployment. Here are some common model evaluation metrics categorized by problem type:\n",
    "\n",
    "#### Classification Metrics\n",
    "\n",
    "1.  **Confusion Matrix**: A table that summarizes the performance of a classification model. It shows the counts of true positive (TP), true negative (TN), false positive (FP), and false negative (FN) predictions.\n",
    "\n",
    "2.  **Accuracy**: The proportion of correctly classified instances out of the total instances. It's useful when classes are balanced.\n",
    "\n",
    "    <img src=\"images/accuracy.jpg\" alt=\"unable to load Accuracy image\" />\n",
    "    \n",
    "4.  **Precision**: The proportion of true positive predictions out of all positive predictions made by the model. It measures the model's ability to avoid false positives.\n",
    "   \n",
    "    <img src=\"images/precision.jpg\" alt=\"unable to load Precision image\" />\n",
    "    \n",
    "6.  **Recall (Sensitivity or True Positive Rate)**: The proportion of true positive instances that are correctly identified by the model. It measures the model's ability to capture all positive instances.\n",
    "\n",
    "    <img src=\"images/recall.jpg\" alt=\"unable to load Recall image\" />\n",
    "    \n",
    "7.  **F1-Score**: The harmonic mean of precision and recall. It provides a single metric that balances both precision and recall.\n",
    "\n",
    "    <img src=\"images/f1score.jpg\" alt=\"unable to load F1-Score image\" />\n",
    "    \n",
    "8.  **ROC Curve (Receiver Operating Characteristic Curve)** and **AUC (Area Under the Curve)**: ROC curve plots the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. AUC represents the degree or measure of separability - the ability of the model to distinguish between classes - with higher values indicating better performance.\n",
    "\n",
    "#### Regression Metrics\n",
    "\n",
    "1.  **Mean Squared Error (MSE)**: The average of the squared differences between predicted and actual values. It emphasizes larger errors due to squaring.\n",
    "\n",
    "    <img src=\"images/mse.jpg\" alt=\"unable to load MSE image\" />\n",
    "    \n",
    "2.  **Root Mean Squared Error (RMSE)**: The square root of MSE, which provides a measure of the average magnitude of error.\n",
    "\n",
    "    <img src=\"images/rmse.jpg\" alt=\"unable to load RMSE image\" />\n",
    "    \n",
    "3.  **Mean Absolute Error (MAE)**: The average of the absolute differences between predicted and actual values. It measures average magnitude of errors.\n",
    "\n",
    "    MAE=1n∑i=1n∣yi-y^i∣\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|MAE=n1​i=1∑n​∣yi​-y^​i​∣\n",
    "4.  **R-squared (Coefficient of Determination)**: A statistical measure that represents the proportion of variance in the dependent variable that is predictable from the independent variables. It ranges from 0 to 1, with 1 indicating perfect prediction.\n",
    "\n",
    "    <img src=\"images/rsquare.jpg\" alt=\"unable to load R-squared image\" />\n",
    "\n",
    "### Considerations\n",
    "\n",
    "-   **Choosing Metrics**: Select metrics based on the specific problem and business objectives. For example, in a medical diagnosis task, recall might be more critical than precision.\n",
    "\n",
    "-   **Trade-offs**: Metrics often involve trade-offs (e.g., precision vs. recall) that need careful consideration based on the application.\n",
    "\n",
    "-   **Evaluation Strategy**: Cross-validation and train-test splits are common strategies to evaluate model performance robustly.\n",
    "4o\n",
    "\n",
    "Expalin \"ML_Tools_and_Libraries\"\n",
    "\n",
    "ChatGPT\n",
    "\n",
    "### ML Tools and Libraries\n",
    "\n",
    "Machine Learning (ML) has grown rapidly, and with it, a plethora of tools and libraries have emerged to support various aspects of the ML lifecycle. These tools and libraries simplify the process of building, training, and deploying ML models. Below are some of the most popular ML tools and libraries, categorized based on their functionality:\n",
    "\n",
    "#### 1\\. **Data Preprocessing and Manipulation**\n",
    "\n",
    "-   **Pandas**: A powerful Python library for data manipulation and analysis. It provides data structures and functions needed to manipulate structured data seamlessly.\n",
    "-   **NumPy**: A fundamental package for numerical computation in Python. It offers support for arrays, matrices, and high-level mathematical functions.\n",
    "-   **SciPy**: An ecosyste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f21ee-7924-48df-972d-21eb026f6c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
